%-----------------------------------------------------------------------------%
%                                                                             %
%    Anhänge					                                             					  %
%                                                                             %
%-----------------------------------------------------------------------------%

\appendix
\chapter{Appendix}

\subsection{Carlos Talk: Essentials}
In the end we want to solve a bilevel (nested) optimization
\begin{equation} 
\begin{split}
\myM{X}^*,\myM{U}^* = \arg\min_{\myM{X},\myM{U}} \sum_{k=0}^{N-1} task(x_k,u_k) \\
x_k=\arg\min physics(x_k,u_k), \\
s.t. \quad constraints(x_k,u_k)
\end{split}
\end{equation}

Which more formally looks like
\begin{equation*} 
\begin{split}
\myM{X}^*,\myM{U}^*=
\begin{Bmatrix} \myM{x}^*_0,\cdots,\myM{x}^*_N \\
      \myM{u}^*_0,\cdots,\myM{u}^*_N
\end{Bmatrix} =
\arg\min_{\myM{X},\myM{U}} l_N(x_N)+\sum_{k=0}^{N-1} \int_{t_k}^{t_k+\Delta t} l(\myM{x},\myM{u})dt \\
s.t.\quad\myM{\dot{v}}, \myM{\lambda}=\arg\min_{\myM{\dot{v}}, \myM{\lambda}}||\myM{\dot{v}}-\myM{\dot{v}}_{free}||_M, \\
\myM{x}\in \mathcal{X}, \myM{u}\in \mathcal{U}
\end{split}
\end{equation*}

KKT Matrix:
\begin{equation*} 
\begin{split}
\myM{X}^*,\myM{U}^* = \arg\min_{\myM{X},\myM{U}} \sum_{k=0}^{N-1} task(x_k,u_k) \\
KKT-Dynamics(x_k,u_k) 
\end{split}
\end{equation*}

Multi-contact dynamics as holonomic constraints:
\begin{equation*} 
\left[\begin{matrix}
  \myM{\dot{v}} \\
  -\myM{\lambda} \\
\end{matrix}\right] 
=
\left[\begin{matrix}
 \myM{M} & \myM{J}^{\top}_c \\
 {\myM{J}_{c}} & \myM{0} \\
\end{matrix}\right]^{-1}
\left[\begin{matrix}
 \myM{\tau}_b \\ -\myM{a_0}
\end{matrix}\right]
\end{equation*}


\section{Crocoddyl: Contact RObot COntrol by Differential DYnamic programming Library (Wiki Home)}
\subsection{Welcome to Crocoddyl}
Crocoddyl is an optimal control library for robot control under contact sequence. Its solver is based on an efficient Differential Dynamic Programming (DDP) algorithm. Crocoddyl computes optimal trajectories along to optimal feedback gains. It uses Pinocchio for fast computation of robot dynamics and its analytical derivatives.
Crocoddyl is focused on multi-contact optimal control problem (MCOP) which as the form:
$$\myM{X}^*,\myM{U}^*= \begin{Bmatrix} \myM{x}^*_0,\cdots,\myM{x}^*_N \\ \myM{u}^*_0,\cdots,\myM{u}^*_N \end{Bmatrix} = \arg\min_{\myM{X},\myM{U}} \sum_{k=1}^N \int_{t_k}^{t_k+\Delta t} l(\myM{x},\myM{u})dt$$
subject to
$$\myM{\dot{x}} = \myM{f}(\myM{x},\myM{u}),$$
$$\myM{x}\in\mathcal{X}, \myM{u}\in\mathcal{U}, \boldsymbol{\lambda}\in\mathcal{K}.$$
where
\begin{itemize}
\item the state $\myM{x}=(\myM{q},\myM{v})$ lies in a manifold, e.g. Lie manifold $\myM{q}\in SE(3)\times \myM{R}^{n_j}$,
\item the system has underactuacted dynamics, i.e. $\myM{u}=(\myM{0},\boldsymbol{\tau})$,
\item $\mathcal{X}$, $\mathcal{U}$ are the state and control admissible sets, and
\item $\mathcal{K}$ represents the contact constraints.
\end{itemize}

Note that $\boldsymbol{\lambda}=\myM{g}(\myM{x},\myM{u})$ denotes the contact force, and is dependent on the state and control.

Let's start by understanding the concept behind crocoddyl design.

\subsection{Action Models}
In crocoddyl, an action model combines dynamics and cost models. Each node, in our optimal control problem, is described through an action model. Every time that we want describe a problem, we need to provide ways of computing the dynamics, cost functions and their derivatives. All these is described inside the action model.
To understand the mathematical aspects behind an action model, let's first get a locally linearize version of our optimal control problem as:
$$\myM{X}^*(\myM{x}_0),\myM{U}^*(\myM{x}_0) = \arg\min_{\myM{X},\myM{U}} = cost_T(\delta\myM{x}_N) + \sum_{k=1}^N cost_t(\delta\myM{x}_k, \delta\myM{u}_k)$$
subject to
$$dynamics(\delta\myM{x}_{k+1},\delta\myM{x}_k,\delta\myM{u}_k)=\myM{0},$$
where
$$cost_T(\delta\myM{x}_k) = \frac{1}{2} \begin{bmatrix} 1 \\ \delta\myM{x}_k \end{bmatrix}^\top \begin{bmatrix} 0 & \myM{l_x}^\top_k \\ \myM{l_x}_k & \myM{l_{xx}}_k \end{bmatrix} \begin{bmatrix} 1 \\ \delta\myM{x}_k \end{bmatrix},$$     

$$cost_t(\delta\myM{x}_k,\delta\myM{u}_k) = \frac{1}{2} \begin{bmatrix} 1 \\ \delta\myM{x}_k \\ \delta\myM{u}_k \end{bmatrix}^\top \begin{bmatrix} 0 & \myM{l_x}^\top_k & \myM{l_u}^\top_k\\ \myM{l_x}_k & \myM{l_{xx}}_k & \myM{l_{ux}}^\top_k\\ \myM{l_u}_k & \myM{l_{ux}}_k & \myM{l_{uu}}_k \end{bmatrix} \begin{bmatrix} 1 \\ \delta\myM{x}_k \\ \delta\myM{u}_k \end{bmatrix}$$

$$dynamics(\delta\myM{x}_{k+1},\delta\myM{x}_k,\delta\myM{u}_k) = \delta\myM{x}_{k+1} - (\myM{f_x}_k\delta\myM{x}_k + \myM{f_u}_k\delta\myM{u}_k)$$

\subsubsection{Notes}
\begin{itemize}
\item An action model describes the dynamics and cost functions for a node in our optimal control problem.
\item Action models lie in the discrete time space.
\item For debugging and prototyping, we have also implemented NumDiff abstractions. These computations depend only in the defining of the dynamics equation and cost functions. However to asses efficiency, crocoddyl uses analytical derivatives computed from Pinocchio.
\end{itemize}

\subsubsection{Differential and Integrated Action Models}

It's often convenient to implement action models in continuous time. In crocoddyl, this continuous-time action models are called Differential Action Model (DAM). And together with predefined Integrated Action Models (IAM), it possible to retrieve the time-discrete action model needed by the solver.
At the moment, we have the following integration rules:
\begin{itemize}
\item simpletic Euler and
\item Runge-Kutta 4.
\end{itemize}

\subsubsection{Add On from Introduction.jpnb}
Optimal control solvers often need to compute a quadratic approximation of the action model (as previously described); this provides a search direction (computeDirection). Then it's needed to try the step along this direction (tryStep).

Typically calc and calcDiff do the precomputations that are required before computeDirection and tryStep respectively (inside the solver). These functions update the information of:
\begin{itemize}
\item \textbf{calc}: update the next state and its cost value
 $$\delta\myM{\dot{x}}_{k+1} = \myM{f}(\delta\myM{x}_k,\myM{u}_k)$$
\item \textbf{calcDiff}: update the derivatives of the dynamics and cost (quadratic approximation)
 $$\myM{f_x}, \myM{f_u} \hspace{1em} (dynamics)$$
 $$\myM{l_x}, \myM{l_u}, \myM{l_{xx}}, \myM{l_{ux}}, \myM{l_{uu}} \hspace{1em} (cost)$$
\end{itemize}


\subsection{State and its Integrate and Difference Rules}
General speaking, the system's state can lie in a manifold $M$ where the state rate of change lies in its tangent space $T_\mathbf{x} M$. There are few operators that needs to be defined for different routines inside our solvers:
$$\myM{x}_{k+1} = integrate(\myM{x}_k,\delta\myM{x}_k) = \myM{x}_k \oplus \delta\myM{x}_k$$
$$\delta\myM{x}_k = difference(\myM{x}_{k+1},\myM{x}_k) = \myM{x}_{k+1} \ominus \myM{x}_k$$
where $\mathbf{x}\in M$ and $\delta\mathbf{x}\in T_\mathbf{x} M$.
And we also need to defined the Jacobians of these operators with respect to the first and second arguments:
$$\frac{\partial \myM{x}\oplus\delta\myM{x}}{\partial \myM{x}}, \frac{\partial \myM{x}\oplus\delta\myM{x}}{\partial\delta\myM{x}} =Jintegrante(\myM{x},\delta\myM{x})$$
$$\frac{\partial\myM{x}_2\ominus\myM{x}_2}{\partial \myM{x}_1}, \frac{\partial \myM{x}_2\ominus\myM{x}_1}{\partial\myM{x}_1} =Jdifference(\myM{x}_2,\myM{x}_1)$$
For instance, a state that lies in the Euclidean space will the typical operators:
$$integrate(\myM{x},\delta\myM{x}) = \myM{x} + \delta\myM{x}$$
$$difference(\myM{x}_2,\myM{x}_1) = \myM{x}_2 - \myM{x}_1$$
$$Jintegrate(\cdot,\cdot) = Jdifference(\cdot,\cdot) = \myM{I}$$
All these functions are encapsulate inside the State class. For Pinocchio models, we have implemented the StateMultibody class which can be used for any robot model.

\section{Crocoddyl Wiki: Differential Action Model for Floating in Contact Systems (DAMFIC)}
\subsection{System Dynamics}
As you might know, a differential action model describes the systems dynamics and cost function in continuous-time. For multi-contact locomotion, we account for the rigid contact by applying the Gauss principle over holonomic constraints in a set of predefined contact placements, i.e.:
$$\begin{aligned} & \dot{\myM{v}} = \underset{\myM{a}}{\arg\min} & & \frac{1}{2}\,\|\dot{\myM{v}}-\dot{\myM{v}}_{free}\|_{\myM{M}} \\ & \textrm{subject to} & & \myM{J}_{c} \dot{\myM{v}} + \dot{\myM{J}}_c \myM{v} = \myM{0}, \end{aligned}$$

This is equality-constrained quadratic problem with an analytical solution of the form:
$$\left[\begin{matrix}\myM{M} & \myM{J}^{\top}_c \\{\myM{J}_{c}} & \myM{0}\end{matrix}\right] \left[\begin{matrix} \dot{\myM{v}} \\ -\boldsymbol{\lambda} \end{matrix}\right] = \left[\begin{matrix} \boldsymbol{\tau}_b \\ -\dot{\myM{J}}_c \myM{v}\end{matrix}\right]$$
in which
$$(\dot{\myM{v}},\boldsymbol{\lambda})\in(\myM{R}^{nv},\myM{R}^{nf})$$
are the primal and dual solutions,
$$\myM{M}\in\myM{R}^{nv\times nv}$$ is formally the metric tensor over the configuration manifold $\myM{q}\in\myM{R}^{nq}$,
$$\myM{J}_{c}= \begin{bmatrix} \myM{J}_{c_1} & \cdots & \myM{J}_{c_f}\end{bmatrix}\in\myM{R}^{nf\times nv}$$ is a stack of $f$ contact Jacobians,
$\boldsymbol{\tau}_b=\myM{S}\boldsymbol{\tau}-\myM{b}\in\myM{R}^{nv}$ is the force-bias vector that accounts for the control $\boldsymbol{\tau}\in\myM{R}^{nu}$, the Coriolis and gravitational effects $\myM{b}$, and $\myM{S}$ is the selection matrix of the actuated joint coordinates, and
$nq$, $nv$, $nu$ and $nf$ are the number of coordinates used to describe the configuration manifold, its tangent-space dimension, control commands and contact forces, respectively.

And this equality-constrained forward dynamics can be formulated using state space representation, i.e.:
$$\dot{\myM{x}}=\myM{f(x,u)}$$
where $\myM{x}=(\myM{q,v})\in\myM{R}^{nq+nv}$ and $\myM{u}=\boldsymbol{\tau}\in\myM{R}^{nu}$ are the state and control vectors, respectively. Note that $\dot{\myM{x}}$ lies in the tangent-space of $\myM{x}$, and their dimension are not the same.

\subsection{Add On from Introduction.jpnb}
\subsection{Solving the Optimal Control Problem}
Our optimal control solver interacts with a defined ShootingProblem. A \textbf{shooting problem} represents a \textbf{stack of action models} in which an action model defines a specific node along the OC problem.

First we need to create an action model from DifferentialFwdDynamics. We use it for building terminal and running action models. In this example, we employ an simpletic Euler integration rule.

Next we define the set of cost functions for this problem. One could formulate
\begin{itemize}
\item Running costs (related to individual states)
\item Terminal costs (related to the final state)
\end{itemize}
in order to penalize, for example, the state error, control error, or end-effector pose error. 

Onces we have defined our shooting problem, we create a DDP solver object and pass some callback functions for analysing its performance.
\subsubsection{Application to Bipedal Walking}
In crocoddyl, we can describe the multi-contact dynamics through holonomic constraints for the support legs. From the Gauss principle, we have derived the model as:
$$
\left[\begin{matrix}
 \myM{M} & \myM{J}^{\top}_c \\
 {\myM{J}_{c}} & \myM{0} \\
\end{matrix}\right]
\left[\begin{matrix}
 \dot{\myM{v}} \\ -\boldsymbol{\lambda}
\end{matrix}\right]
 = 
\left[\begin{matrix}
  \boldsymbol{\tau} - \myM{h} \\
  -\dot{\myM{J}}_c \myM{v} \\
\end{matrix}\right]$$.

This DAM is defined in "DifferentialActionModelFloatingInContact" class.
Given a predefined contact sequence and timings, we build per each phase a specific multi-contact dynamics. Indeed we need to describe \textbf{multi-phase optimal control problem}. One can formulate the multi-contact optimal control problem (MCOP) as follows:

$$\myM{X}^*,\myM{U}^*=
\begin{Bmatrix} \myM{x}^*_0,\cdots,\myM{x}^*_N \\
				  \myM{u}^*_0,\cdots,\myM{u}^*_N
\end{Bmatrix} =
\arg\min_{\myM{X},\myM{U}} \sum_{p=0}^P \sum_{k=1}^{N(p)} \int_{t_k}^{t_k+\Delta t} l_p(\myM{x},\myM{u})dt$$
subject to
$$ \myM{\dot{x}} = \myM{f}_p(\myM{x},\myM{u}), \text{for } t \in [\tau_p,\tau_{p+1}]$$

$$ \myM{g}(\myM{v}^{p+1},\myM{v}^p) = \myM{0}$$

$$ \myM{x}\in\mathcal{X}_p, \myM{u}\in\mathcal{U}_p, \boldsymbol{\lambda}\in\mathcal{K}_p.$$

where $\myM{g}(\cdot,\cdot,\cdot)$ describes the contact dynamics, and they represents terminal constraints in each walking phase. In this example we use the following \textbf{impact model}:

$$\myM{M}(\myM{v}_{next}-\myM{v}) = \myM{J}_{impulse}^T$$

$$\myM{J}_{impulse} \myM{v}_{next} = \myM{0}$$

$$\myM{J}_{c} \myM{v}_{next} = \myM{J}_{c} \myM{v}$$

